# Task#10. Classification comparison
Задачу выполняла в [Google Colab](https://colab.research.google.com/drive/1f6EUuZ7m0ZWAnnb2VqK6Fuca41mGBbPf?usp=sharing), ссылка на сам ноутбук также есть в README.md всего репозитория.

Эта же папка, в свою очередь, дублирует его.
---
### Описание выполненной работы

#### 1. **Подготовка данных**
   - Выбран набор данных [Zoo](https://archive.ics.uci.edu/dataset/111/zoo), содержащий информацию о характеристиках различных животных и их классе.
   - Выполнена загрузка и первичный анализ данных:
     - Проверены пропущенные значения.
     - Оценены распределения данных по классам.


#### 2. **Анализ данных (EDA)**
   - Проведён разведочный анализ данных, включающий:
     - Анализ распределения по классам.
     - Исследование корреляций между признаками.
   - Использованы графики (гистограммы, scatter) для визуального анализа данных.


#### 3. **Обучение моделей и сравнение методов классификации**
    - Для подготовки данных проведены:
     - Разделение на тестовую и обучающую выборку (30/70)
     - Масштабирование признаков с использованием `StandardScaler`.
   - Обучены и настроены четыре модели:
     - **Decision Tree**
     - **Random Forest**
     - **Logistic Regression**
     - **K-Nearest Neighbors (KNN)**
   - Для каждой модели выполнены:
     - Подбор гиперпараметров.
     - Кросс-валидация.
     - Построение и анализ метрик классификации (accuracy, precision, recall, F1-score).
   - Для анализа ошибок построены **confusion matrices**.


#### 4. **Визуализация данных и результатов**
   - Выполнено понижение размерности данных для визуализации с помощью **PCA** и **t-SNE**.
   - Построены scatter-plots для визуализации распределения данных по истинным и предсказанным меткам.
   - Проведён анализ кластеров и областей, в которых модели испытывают затруднения при классификации.


#### 5. **Выводы**
   - Сравнены результаты всех моделей:
     - **Decision Tree и Logistic Regression** достигают идеальных результатов на текущем наборе данных.
     - **Random Forest** показал сбалансированную производительность и устойчивость, но требует улучшения в классификации редких классов.
     - **KNN** оказался наименее точным, но имеет потенциал на более крупных выборках.
   - Проведён общий анализ сильных и слабых сторон каждой модели.
   - Даны рекомендации по дальнейшему преобразованию данных и настройке моделей в задачах классификации.


Каждый этап сопровождался пояснениями в Markdown, и финальная работа представлена в `classification_comparison.ipynb`
